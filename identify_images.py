# -*- coding: utf-8 -*-
"""hw5_ml.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zVk1cX1vVqr1oiTAe-a_fH99npZScSrr
"""

# Commented out IPython magic to ensure Python compatibility.
import torchvision
import torch
import numpy as np
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import torch.nn as nn
from google.colab import drive
drive.mount('/content/drive')
# %matplotlib inline

transforms = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
        ])
train_set = datasets.ImageFolder("/content/drive/My Drive/data/train",transforms)
    
val_set = datasets.ImageFolder("/content/drive/My Drive/data/val",transforms)
model = models.resnet34(pretrained=True)

fc_features = model.fc.in_features
model.fc = nn.Linear(fc_features, 2)

trainDataLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)
testDataLoader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=False)
images, labels = iter(trainDataLoader).next()
print(train_set.class_to_idx)
print(train_set.classes)

Loss = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

train_loss_history = []
test_loss_history = []
num_epochs = 20

for epoch in range(num_epochs):
  train_loss = 0.0
  test_loss = 0.0
  for i, data in enumerate(trainDataLoader):
    images, labels = data
    optimizer.zero_grad()
    predicted_output = model(images)
    fit = Loss(predicted_output,labels)
    fit.backward()
    optimizer.step()
    train_loss += fit.item()
  for i, data in enumerate(testDataLoader):
    with torch.no_grad():
      images, labels = data
      predicted_output =model(images)
      fit = Loss(predicted_output,labels)
      test_loss += fit.item()
  train_loss = train_loss/len(trainDataLoader)
  test_loss = test_loss/len(testDataLoader)
  train_loss_history.append(train_loss)
  test_loss_history.append(test_loss)
  print('Epoch %s, Train loss %s, Test loss %s'%(epoch, train_loss, test_loss))

plt.plot(np.arange(num_epochs),train_loss_history,'-',linewidth=3,label='Train error')
plt.plot(np.arange(num_epochs),test_loss_history,'-',linewidth=3,label='Test error')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.grid(True)
plt.legend()

def evaluate(dataloader):
  total, correct = 0, 0
  model.eval() # don't update weights
  for data in dataloader:
    images, labels = data
    predicted_output = model(images)
    _, predicted_labels = torch.max(predicted_output,1)
    total += labels.size(0)
    correct += (predicted_labels == labels).sum().item()
  return 100 * correct/total

print('Train acc = %0.2f, test acc = %0.2f' % (evaluate(trainDataLoader), evaluate(testDataLoader)))

images, labels = iter(testDataLoader).next()
predicted_output = model(images)
_, predicted_labels = torch.max(predicted_output,1)

predicted_labels = predicted_labels.cpu().numpy()

from sklearn import metrics
conf_matrix = metrics.confusion_matrix(labels, predicted_labels)

import seaborn as sns
plt.figure(figsize=(6,6))
sns.heatmap(conf_matrix, annot=True, square = True)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.show()